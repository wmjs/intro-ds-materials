{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "456b4db9",
   "metadata": {},
   "source": [
    "# Section 6 - Basic Bayesian Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7350497",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 1. Summary of Bayesian Inference\n",
    "\n",
    "In this activity, you will explore the problem of estimating probabilities from data using Bayesian faremework: \n",
    "1. **start** with our current knowledge (prior) on the paramater of interest $\\theta$\n",
    "2. **update** our knowledge according to some observed data $x_1, \\dots, x_n$.\n",
    "\n",
    "Because the parameter of interest is treated as a random variable with a distribution, we call the random variable $\\Theta$ and the specific observed value $\\theta$.\n",
    "\n",
    "Based on the Bayes' theorom, the **_posterior_** distribution incorporates a vector of observations $x = (x_1, \\dots, x_n)$ into the distribution of $\\Theta$. The posterior distribution may be thought of as the prior distribution modified with observed data. The formula of the posterior distribution is\n",
    "$$\n",
    "p(\\theta | x) \\ = \\ \\frac{p(x|\\theta)p(\\theta)}{\\int_{\\theta}\\ p(x|\\theta)p(\\theta) \\ d\\theta} \\ = \\ \\frac{\\text{likelihood} \\cdot \\text{prior}}{\\text{normalizing constant}}.\n",
    "$$\n",
    "- $p(x|\\theta)$ is the **likelihood** that we see the observed data, given parameter $\\theta$.\n",
    "- $p(\\theta)$ is the **prior** distribution that captures our knowledge about the $\\theta$ before seeing the observed data. In other words, prior distribution describes our best guess about $\\theta$ before observing the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8bee55",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eabb41c-d3ff-41d9-835d-3e303919ed23",
   "metadata": {},
   "source": [
    "# 2. Estimating Chemotherapy Response Rates\n",
    "Efficacy of a new chemotherapy medication is under investigation. Use Bayesian inference to judge if the medication actually works.\n",
    "- $\\theta$ is the parameter of interest, the success rate of the medication.\n",
    "\n",
    "- $x_1, \\dots, x_n$ are the samples of whether the medication worked on test subjects.\n",
    "    - 1 represents successful  medication\n",
    "    - 0 represents unsuccessful/no response to medication. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8dc3eae",
   "metadata": {},
   "source": [
    "## 2.1 Prior distribution: beta $p(\\theta)$\n",
    "### Preliminary results\n",
    "Based on a preliminary results (prior) with 10 samples it is believed that:\n",
    "- prior mean: on average $\\theta=$ 90% of patients will respond successfully to this medication. \n",
    "- prior std: with high probability (>95%), the success rate will not go below 80%. \n",
    "\n",
    "**Discuss:** \n",
    "1. What prior distribution should we use? \n",
    "    \n",
    "    (Hint: the prior has to take on values only between 0 and 1. What distributions do we know does that? What distributions are ill-suited?)\n",
    "\n",
    "    **Ans:** \n",
    "\n",
    "2. According to the preliminary results, why can make the approximation that\n",
    "    $$\\mu = 0.9 \\quad \\text{ and } \\quad \\mu - 2\\sigma=0.8?$$\n",
    "\n",
    "    **Ans:** \n",
    "\n",
    "\n",
    "3. Thomas thinks that Bernoulli makes better sense because chemotherapy is about probability of success. How is he mistaken? \n",
    "    \n",
    "    (Bonus: Thomas is the name of which famous statistician?)\n",
    "\n",
    "    **Ans:** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7993ee4a",
   "metadata": {},
   "source": [
    "### Beta prior\n",
    "**Task:** \n",
    "\n",
    "Based on the above information, code up the prior.\n",
    "1. Define prior mean ```mu``` and prior standard deviation ```sigma``` using the preliminary result and investigators' beliefs.\n",
    "2. Define prior Beta(a,b) distribution parameters ```a``` and ```b```, using ```mu``` and ```sigma``` defined earlier. \n",
    "\n",
    "    How? You will need to invert \n",
    "    $$\n",
    "    \\mu = E[\\Theta] = \\frac{a}{a+b} \\quad \\text{ and } \\quad \\sigma^2 = E[\\Theta^2] = \\frac{ab}{(a+b)^2(a+b+1)}.\n",
    "    $$ \n",
    "    We do this for you\n",
    "    $$\n",
    "    a = \\mu\\left( \\frac{\\mu(1-\\mu)}{\\sigma^2} - 1\\right) \\quad \\text{ and } \\quad b = (1-\\mu)\\left( \\frac{\\mu(1-\\mu)}{\\sigma^2} - 1\\right),\n",
    "    $$\n",
    "    which is the method of moments in the formula table given in [Wiki: Beta](https://en.wikipedia.org/wiki/Beta_distribution#:~:text=Beta%20function.-,Beta,-Probability%20density%20function).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1b40a7-270a-4668-bd8a-ea2d076d6d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean and standard deviation\n",
    "mu    = None    # TODO\n",
    "sigma = None    # TODO\n",
    "\n",
    "# using method of moments to define the beta distribution parameters a an b\n",
    "a = None    # TODO\n",
    "b = None    # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28beb13",
   "metadata": {},
   "source": [
    "3. Define `theta` an array that represents the horizontal axis/range of parameters we are computing the posterior for. \n",
    "4. Define `prior`, an array of prior probabilities $p(\\theta)$ for each parameter $\\theta$.\n",
    "    - call the beta pdf function stats.beta.pdf().\n",
    "5. Plot `prior` against `theta`. \n",
    "    - You should have at least 100 points.\n",
    "    - Note that domain/support of Beta is always [0,1].\n",
    "6. Verify that the shape of the plotted prior density is consistent with the preliminary results described earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fc2033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# domain Î¸\n",
    "theta = None                                        # TODO\n",
    "prior = stats.beta.pdf(x=None, a=None, b=None)      # TODO\n",
    "\n",
    "# plot\n",
    "plt.plot(theta, prior, 'r')\n",
    "\n",
    "plt.title(f'PDF of $\\Theta \\sim B({a:.1f},{b:.1f})$, Chemotherapy Response Rate'); \n",
    "plt.xlabel(r'$\\theta$'); plt.ylabel(r'Density, $f_{\\Theta}(\\theta)$')\n",
    "plt.grid(alpha=.4, linestyle='--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93456980-e9e3-4a08-82b3-a44bc7e9d2cf",
   "metadata": {},
   "source": [
    "## 2.2 Likelihood: binomial $p(x|\\theta)$\n",
    "### New trial data\n",
    "During a new trial ($n=30$), the following data was collected\n",
    "$$x = [1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1] \\in \\{0,1\\}^{30}.$$\n",
    "- 1 represents successful  medication\n",
    "- 0 represents unsuccessful/no response to medication. \n",
    "\n",
    "**Discuss:**\n",
    "Run the cell below. Before we continue with Bayesian analysis, intuitively, do you think the 10 preliminary result/prior distribution (mean = 0.9, std=0.05) is  consistent with the 30 observed data from the new trial? \n",
    "\n",
    "**Ans:** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1d7fe1-fa32-4772-a1f4-9b13ccf504e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_data = np.array([1,0,1,1,1,0,0,1,1,1,0,1,1,0,1,1,1,1,0,1,1,1,0,1,1,1,0,1,1,1])\n",
    "print('mean of trial data:', np.mean(trial_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69d27c0",
   "metadata": {},
   "source": [
    "### Binomial likelihood\n",
    "A suitable likelihood function $p(x|\\theta)$ is binomial(n,$\\theta$).\n",
    "\n",
    "**Discuss:**\n",
    "1. Why might Binomial be reasonable for the observed trial data/likelihood?\n",
    "\n",
    "    **Ans:** \n",
    "\n",
    "2. What is the formula for Binomial likelihood $p(x|\\theta)$, probability of $x$ successes in $n$ trials? \n",
    "\n",
    "    **Ans:** \n",
    "\n",
    "3. Does the likelihood function integrate to 1? I.e., does $\\int_0^1 p(x|\\theta) d\\theta = 1$? What does it tells us about the difference between a likelihood function and a probability density?\n",
    "\n",
    "    **Ans:** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97023388",
   "metadata": {},
   "source": [
    "**Task:** \n",
    "\n",
    "1. `likelihood`, which is an array of likelihoods $p(x|\\theta)$ for each $\\theta$\n",
    "    - call the stats.binom.pmf() function. In the arguments for the function:\n",
    "    - number of successes `k` and total number of trials `n` is fixed.\n",
    "    - success probability `p` (which is $\\theta$ we are trying to infer) is variable. You should input `theta` defined earlier here.\n",
    "2. Plot `likelihood` against `theta`.\n",
    "\n",
    "The plot shows the probability of observing fixed sample $x = (x_1, \\dots, x_n)$ above, but changing parameter values $\\theta$'s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b84879a",
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood = None        # TODO\n",
    "\n",
    "plt.plot(theta, likelihood)\n",
    "\n",
    "plt.title(f'Likelihood of Bin$({len(trial_data):d},\\\\theta)$')\n",
    "plt.xlabel(r'$\\theta$'); plt.ylabel(r'likelihood, $p(x|\\theta)$')\n",
    "plt.grid(alpha=.4, linestyle='--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9630d6f7-c988-4d23-b1d1-90b4f58fcacf",
   "metadata": {},
   "source": [
    "## 2.3 Posterior Distribution: $p(\\theta|x)$\n",
    "\n",
    "Recall, the formula of the posterior distribution is\n",
    "$$\n",
    "p(\\theta | x) \\ = \\ \\frac{p(x|\\theta)p(\\theta)}{\\int_{\\theta}  \\ p(x|\\theta)p(\\theta) \\ d\\theta} \\ = \\ \\frac{\\text{likelihood} \\cdot \\text{prior}}{\\text{normalizing constant}}.\n",
    "$$\n",
    "Our next goal is to compute the posterior step-by-step, using the prior and likelihood computed earlier.\n",
    "\n",
    "**Task:**\n",
    "1. Compute the numerator of the posterior `post_nume`, $p(x|\\theta)p(\\theta)$ \n",
    "    - multiply `likelihood` and `prior`.\n",
    "2. Compute the denominator of the posterior `post_denom`, $\\int_{\\theta}p(x|\\theta)p(\\theta)d\\theta$.\n",
    "    - method 1: np.trapz(), which integrates the area under the \"curve\". For this approximation to be accurate, `theta` must be a long/dense array with many points.\n",
    "    - method 2: stats.betabinom.pmf(), which is exactly the distribution of the numerator! Key in relevant parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4970ce58-44e1-4f7a-9bc7-e35165c21e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_nume = None      # TODO\n",
    "\n",
    "post_denom = None       # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c0dd84",
   "metadata": {},
   "source": [
    "**Task:**\n",
    "1. Compute `posterior` an array of posterior probabilities $p(\\theta | x)$\n",
    "    - `post_nume` divide `post_denom`\n",
    "2. Plot the posterior density.\n",
    "3. Plot the prior density and likelihood on the same figure too. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e125b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior = None          # TODO\n",
    "\n",
    "# optional, but good sanity check.  check the area of posterior distribution\n",
    "area_posterior = np.trapz(posterior, theta)\n",
    "print(f'Area under the curve for the posterior is {area_posterior}')\n",
    "\n",
    "# plot the prior, likelihood, and posterior probabilities\n",
    "plt.plot(theta, prior, 'r', label=\"Prior\")\n",
    "plt.plot(theta, posterior, 'g', label='Posterior')\n",
    "plt.grid(alpha=.4, linestyle='--')\n",
    "plt.xlabel(r'$\\theta$'); plt.ylabel('density'); plt.legend()\n",
    "plt.title('Prior vs Posterior')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968e01e3",
   "metadata": {},
   "source": [
    "**Discuss:**\n",
    "1. Given the posterior plot, how can we find a possible prediction $\\widehat{\\theta}$ for the parameter of interest $\\theta$? What makes sense for the \"most likely\" value of $\\theta$? \n",
    "\n",
    "    **Ans:** \n",
    "\n",
    "2. Compute `theta_hat`, the predictor $\\widehat{\\theta}$.\n",
    "    - it might help to use np.argmax()\n",
    "\n",
    "3. Plot the posterior density and a dotted vertical line $\\theta = \\widehat{\\theta}$ for the predictor $\\widehat{\\theta}$ you decided on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0377e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get candidate theta by computing theta that maximizes posterior, i.e., the posterior mode.\n",
    "# another candidate is posterior mean\n",
    "theta_hat = None            # TODO\n",
    "\n",
    "plt.plot(theta, posterior, label='Posterior', color='g')\n",
    "plt.axvline(x= theta_hat, color='red', linestyle='--')\n",
    "plt.text(theta_hat + 0.02, 8, r'$\\widehat{\\theta_{MAP}}$='+f'{theta_hat:.2f}', fontsize=15)\n",
    "plt.grid(alpha=.4, linestyle='--')\n",
    "plt.xlabel(r'$\\theta$'); plt.ylabel('density'); plt.legend()\n",
    "plt.title('Posterior density')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c4f677-5cc4-48d8-81a0-57bf72adc99f",
   "metadata": {},
   "source": [
    "# Appendix: Conjugate priors and beta-binomial (good to understand if you want to pursue further applied math)\n",
    "\n",
    "A major difficulty in Bayesian analysis is finding an explicit posterior distribution, given the likelihood and prior. \n",
    "\n",
    "The posterior is proportional to the product of the likelihood and prior, but the normalizing constant/marginal distribution in the denominator, is often difficult to compute since it involves integration. \n",
    "\n",
    "In today's section, we had binomial likelihood and beta prior. The binomial **likelihood** is\n",
    "$$\n",
    "p(x|\\theta) = \\binom{n}{x}\\theta^{x}(1-\\theta)^{n-x},\n",
    "$$\n",
    "where $\\theta$ is the response rate parameter of interest.\n",
    "\n",
    "For a beta **prior**, we will have the prior distribution\n",
    "$$\n",
    "p(\\theta) = \\frac{1}{B(a,b)}\\theta^{a-1}(1-\\theta)^{b-1},\n",
    "$$\n",
    "where $B(\\cdot,\\cdot)$ is the beta function which itself normalizes function to make it a density that integrates to 1.\n",
    "\n",
    "The **posterior** is proportional to the product of the likelihood and the prior\n",
    "$$\n",
    "p(\\theta|x) = C\\cdot\\theta^{x}(1-\\theta)^{n-x}\\cdot\\theta^{a-1}(1-\\theta)^{b-1} = C\\cdot\\theta^{x+a-1}(1-\\theta)^{n-x+b-1},\n",
    "$$\n",
    "where C is the normalizing constant \n",
    "$$\n",
    "C = \\binom{n}{x}\\frac{1}{p(x)B(a,b)}.\n",
    "$$\n",
    "\n",
    "We see that the posterior density remains beta (amazing!) with parameters $x+a$ and $n-x+b$, and with normalizing constant $\\frac{1}{B(x+a,n-x+b)}$. Therefore, we can infer that the above equation for $C$ is really just\n",
    "$$\n",
    "\\begin{align}\n",
    "& \\frac{\\binom{n}{x}}{p(x)B(a,b)} = C = \\frac{1}{B(x+a,n-x+b)} \\\\\n",
    "& \\implies p(x) = \\frac{\\binom{n}{x}B(x+a,n-x+b)}{B(a,b)},\n",
    "\\end{align}\n",
    "$$\n",
    "which is known as a beta-binomial distribution. \n",
    "\n",
    "In this example, the effect of likelihood is only to update the prior parameters and not to change the priorâs functional form. Such priors are **conjugate** with the likelihood.\n",
    "\n",
    "Note that our initial guess about parameters was $p(\\theta)$. Now that more data were made availabe, we are upgrading our prior information into a more informative guess $p(\\theta|x)$. A possible estimator for $\\theta$ is obtained by finding the $\\theta$ which maximizes the value of posterior distribution (**maximum a posteriori [MAP]**)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835c8f40",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "43129c23d79667d987760d8fda822d6cf9b94e4f6ff31aa29025e95d3c53fe91"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
