{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ca9faff",
   "metadata": {},
   "source": [
    "# Section 3 - Kernel Density Estimation (KDE) and Least Squares\n",
    "You should have downloaded:\n",
    "- wings.csv\n",
    "- housing.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af31e3d",
   "metadata": {},
   "source": [
    "# 1 Least Squares\n",
    "Let's learn to use the sklearn package for least squares linear regression.\n",
    "## 1.1 Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb6837f",
   "metadata": {},
   "outputs": [],
   "source": [
    "######## DO NOT CHANGE THIS CODE ##########\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"housing.csv\")\n",
    "\n",
    "# extract price and lotsize columns as np arrays\n",
    "X, y =  np.array(df['lotsize']), np.array(df['price'])\n",
    "\n",
    "# print the shapes of X and Y\n",
    "print(X.shape); print(y.shape)\n",
    "###########################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054ae47a",
   "metadata": {},
   "source": [
    "## 1.2 Split data into training and testing\n",
    "**Task:** \n",
    "1. Create new numpy column arrays called `X_train, X_test, y_train, y_test`, where:\n",
    "    - you use train_test_split() function from sklearn.model_selection\n",
    "    - the training dataset contains the 70% of samples\n",
    "    - the testing dataset contains the 30% of samples\n",
    "    - random state set to 0.\n",
    "2. Check the dimensions/size of each array and make sure the train-test split is doing what its expected to do. \n",
    "3. Discuss: what other code can you write to verify that the split is indeed randomized and not the original ordering of the given dataset?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aad4e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO split train and test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = None\n",
    "\n",
    "print('X_train: ', X_train.shape)\n",
    "print('X_test : ', X_test.shape)\n",
    "print('y_train: ', y_train.shape)\n",
    "print('y_test : ', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857e827d",
   "metadata": {},
   "source": [
    "## 1.3 Perform linear regression\n",
    "Suppose we model housing price $Y$ by the variable $X$ lot size using the linear model\n",
    "$$\n",
    "Y = aX+b,\n",
    "$$\n",
    "where $a$ and $b$ are coefficients to be determined.\n",
    "\n",
    "**Task:** By looking at the documentation for sklearn.linear_model.LinearRegresson, learn how to:\n",
    "- create a LinearRegression() object/model,\n",
    "- fit the model to the training data (You may need to reshape the data to column arrays by array.reshape(-1,1)),\n",
    "- extract coefficients $a$ and $b$, and then print them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ee88a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# TODO sklearn linear regression model and fit data\n",
    "reg = None\n",
    "\n",
    "\n",
    "# TODO extract coefficients\n",
    "a = None\n",
    "b = None\n",
    "\n",
    "# TODO print coefficients\n",
    "print('a = ', a)\n",
    "print('b = ', b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8433d821",
   "metadata": {},
   "source": [
    "## Manual Linear Regression by Summation\n",
    "\n",
    "Recall: $$\\beta_{i}  = \\frac{\\sum(x_{i}-\\bar{x})(y_{i} - \\bar{y})}{\\sum(x_{i} - \\bar{x})^2}$$ \\\n",
    "        $$\\hat{\\beta}_{0} = \\bar{y}-\\bar{\\beta}_{1}\\hat{x}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afffa21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a = 7.446910160908254\n",
      "b = 29363.804930288556\n"
     ]
    }
   ],
   "source": [
    "#TODO Calculate initial values\n",
    "# What is are the consants in the summation?\n",
    "\n",
    "#TODO Calculate coefficients\n",
    "# Hint break it down into caculating a numerator and denominator\n",
    "\n",
    "#TODO get coefficients\n",
    "beta1 = None\n",
    "beta0 = None\n",
    "\n",
    "print(\"a =\", beta1)\n",
    "print(\"b =\", beta0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0a1d84",
   "metadata": {},
   "source": [
    "# 2 KDE\n",
    "## 2.1 Intro and Data\n",
    "The following exercise is based on Tarn Duong, [\"An Introduction to Kernel Density Estimation.\"](https://www.mvstat.net/tduong/research/seminars/seminar-2001-05/) \n",
    "\n",
    "**Task**:\n",
    "Run the code in the next cell, which loads a sample of the log wingspans of aircraft built from 1956 to 1984 (original wingspans were in meters). \n",
    "- Assume the data are sampled from a continuous distribution with a **bimodal** density, where the peaks in the density represent the modal log wingspans of small and large aircraft respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f30345e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "wings = np.loadtxt('wings.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074594b3",
   "metadata": {},
   "source": [
    "## 2.2 Density estimation via histograms\n",
    "Histograms are dependent on bin width as well as bin boundaries. \n",
    "\n",
    "Varying either of these can obscure features of the distribution from which a sample is drawn. We may gain or lose the appearance of bimodality.\n",
    "    \n",
    "**Task:**\n",
    "On separate figures:\n",
    "- Plot a histogram of the data using bins of width 0.50, where the first bin is [1.00, 1.50).\n",
    "- Plot a histogram of the data using bins of width 0.50, where the first bin is [1.25, 1.75)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302fcd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3793229",
   "metadata": {},
   "source": [
    "### How does kernel density estimation work? \n",
    "- Read [Wikipedia: Kernel density estimation - Definition](https://en.wikipedia.org/wiki/Kernel_density_estimation#Definition)\n",
    "- A useful formula for the estimate of the density is $$\\hat{f_h}(x) = \\frac{1}{nh} \\sum_{i=1}^n K(\\frac{x-x_i}{h}),$$ where $h$ is the bandwidth and $K(\\cdot)$ is the kernel function. \n",
    "- Advantage of kernel density estimation: it does not depend on bin boundaries. It does however depend on bandwidth, which is an analogue of bin width."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bea1941",
   "metadata": {},
   "source": [
    "## 2.3 Density estimation via KDE (Uniform kernel)\n",
    "**Task:**\n",
    "- Write a function `ukde`, which returns a uniform kernel density estimate given:\n",
    "    - a vector of points on the x-axis `x` (the axis of the density)\n",
    "    - a vector of data `data` and \n",
    "    - a bandwidth `h`. \n",
    "Your kernel function $K$ should be the density function of the uniform distribution on $[-1,1]$.\n",
    "- Plot the KDE with uniform kernel for x in the range [1,5]\n",
    "    - Find a bandwidth `bw` that makes bimodality apparent and plot the results. State where the two modes appear to be.\n",
    "- Check that the density estimate integrates to 1 (closer to 1 if number of point on x-axis goes to infinity)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d640ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stat\n",
    "\n",
    "# x: Points at which to evaluate the density estimate.\n",
    "# data: Points on which to base the density estimate.\n",
    "# h: Bandwidth.\n",
    "def ukde(x, data, h):\n",
    "\tn = None\n",
    "\tf = None\n",
    "\tfor j in range(len(x)):\n",
    "\t\tf[j] = None\n",
    "\treturn f\n",
    "\n",
    "# Plot.\n",
    "x = None\n",
    "bw = None\n",
    "plt.plot(x, ukde(x, wings, bw))\n",
    "plt.show()\n",
    "\n",
    "# Check that the density estimate integrates to 1\n",
    "print('area under KDE:', np.trapz(ukde(x, wings, bw), x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3720e277",
   "metadata": {},
   "source": [
    "# 2.4 Density estimation via KDE (Gaussian kernel)\n",
    "\n",
    "Now, instead of uniform kernels, try Gaussian (i.e., normal distribution) kernels. \n",
    "- Advantage of Gaussian kernels over uniform kernels: smoother estimated density curve.\n",
    "\n",
    "**Task:**\n",
    "- Write function `gkde` that returns a Gaussian kernel density estimate given:\n",
    "    - a vector of points on the x-axis `x` (the axis of the density)\n",
    "    - a vector of data `data` and \n",
    "    - a bandwidth `h`. \n",
    "Your kernel function $K$ should be the density function of the standard normal distribution.\n",
    "- Plot the KDE with Gaussian kernel for x in the range [1,5]\n",
    "    - Find a bandwidth `bw` that makes bimodality apparent and plot the results. State where the two modes appear to be.\n",
    "- Check that the density estimate integrates to 1 (closer to 1 if number of point on x-axis goes to infinity)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f756abc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian kernel density estimation.\n",
    "def gkde(x, data, h):\n",
    "        n = None\n",
    "        f = None\n",
    "        for j in range(len(x)):\n",
    "                f[j] = None\n",
    "        return f\n",
    "\n",
    "#2 Plot\n",
    "x = None\n",
    "bw = None\n",
    "plt.plot(x, gkde(x, wings, bw))\n",
    "plt.show()\n",
    "\n",
    "# Check that the density estimate integrates to 1.\n",
    "print('area under KDE:', np.trapz(gkde(x, wings, bw), x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f943eed1",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "43129c23d79667d987760d8fda822d6cf9b94e4f6ff31aa29025e95d3c53fe91"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
