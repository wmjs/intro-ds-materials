{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 6 - Data Splitting, Support Vector Machines\n",
    "\n",
    "You shold have downloaded:\n",
    "- pulsar.csv\n",
    "\n",
    "## 0 Load Data\n",
    "Pulsars are a rare type of Neutron star that produce radio emission detectable here on Earth. They are of considerable scientific interest as probes of space-time, the inter-stellar medium, and states of matter.\n",
    "\n",
    " You can read more (interesting!) details at ([source](https://archive.ics.uci.edu/ml/datasets/HTRU2)).\n",
    "\n",
    "`pulsar.csv`  contains statistics from two types of signal from pulsar candidates: \n",
    "1. integrated profile (IP) and \n",
    "2. dispersion-measure signal-to-noise ratio (DMSNR) curve. \n",
    "\n",
    "Run the cell below to see what data we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- DO NOT CHANGE CODE HERE ---------\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = pd.read_csv(\"pulsar.csv\")\n",
    "display(data)\n",
    "X = data.iloc[:,:8].to_numpy()\n",
    "y = data.iloc[:,8].to_numpy()\n",
    "# --------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Data Splitting (3 ways)\n",
    "There are many ways to split the training and test data. Here is a short exercise to learn and compare 3 such ways using `sklearn.model_selection`:\n",
    "1. `train_test_split`\n",
    "2. `KFold`\n",
    "3. `StratifiedShuffleSplit`\n",
    "\n",
    "**Read and understand** how the 3 methods work by reading the code demostration below.\n",
    "- You should know what every line of code is doing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 1: train_test_split \n",
    "Using `sklearn.model_selection.train_test_split`, we split the data into training and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- DO NOT CHANGE CODE HERE ---------\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_tts, X_test_tts, y_train_tts, y_test_tts = train_test_split(X, y, test_size=1/3, shuffle=False)\n",
    "\n",
    "n_pulsar_train_tts = (y_train_tts==1).sum()\n",
    "n_pulsar_test_tts = (y_test_tts==1).sum()\n",
    "print(\"Training Set, Pulsars:\", n_pulsar_train_tts, \"out of\", y_train_tts.shape[0])\n",
    "print(\"Test Set    , Pulsars:\", n_pulsar_test_tts, \"out of\", y_test_tts.shape[0])\n",
    "# --------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 2: K-Fold\n",
    "Using `sklearn.model_selection.KFold` on default shuffle settings, we split the data into training and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- DO NOT CHANGE CODE HERE ---------\n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=3) \n",
    "\n",
    "for i, (train_idx_kf, test_idx_kf) in enumerate(kf.split(X)):\n",
    "    X_train_kf, y_train_kf = X[train_idx_kf], y[train_idx_kf]\n",
    "    X_test_kf, y_test_kf = X[test_idx_kf], y[test_idx_kf]\n",
    "\n",
    "    n_pulsar_train_kf = (y_train_kf==1).sum()\n",
    "    n_pulsar_test_kf = (y_test_kf==1).sum()\n",
    "    print(\"Training Set, Pulsars:\", n_pulsar_train_kf, \"out of\", y_train_kf.shape[0])\n",
    "    print(\"Test Set    , Pulsars:\", n_pulsar_test_kf, \"out of\", y_test_kf.shape[0], '\\n')\n",
    "# --------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 3: Stratified Shuffle Split\n",
    "Using `sklearn.model_selection.StratifiedShuffleSplit`, we split the data into training and test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- DO NOT CHANGE CODE HERE ---------\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=3, test_size=1/3, random_state=0)\n",
    "\n",
    "X_train_sss, y_train_sss, X_test_sss, y_test_sss = {}, {}, {}, {}\n",
    "for i, (train_idx, test_idx) in enumerate(sss.split(X, y)):\n",
    "    X_train_sss[i], y_train_sss[i] = X[train_idx], y[train_idx]\n",
    "    X_test_sss[i], y_test_sss[i] = X[test_idx], y[test_idx]\n",
    "\n",
    "    n_pulsar_train = (y_train_sss[i]==1).sum()\n",
    "    n_pulsar_test = (y_test_sss[i]==1).sum()\n",
    "    print(\"Training Set, Pulsars:\", n_pulsar_train, \"out of\", y_train_sss[i].shape[0])\n",
    "    print(\"Test Set    , Pulsars:\", n_pulsar_test, \"out of\", y_test_sss[i].shape[0], '\\n')\n",
    "# --------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Discussion (Stratified Shuffle Split)\n",
    "The number of pulsars in the training and test data for stratified shuffle split are identical.\n",
    "\n",
    "**Task:**\n",
    "1. [1 pt] Why are the number of pulsars identical for each stratified shuffle split? (i.e., what does \"stratified\" mean?)\n",
    "\n",
    "    **Ans:** \n",
    "\n",
    "2. [1 pt] Using the code cell below, verify that the splits are actually not identical. (Tip: use np.all(...), where ... is code you fill in yourself.)\n",
    "\n",
    "3. [1 pt] Why is the number of pulsars for stratified shuffle split different from those of train_test_split and KFold? A short answer will do.\n",
    "        \n",
    "    **Ans:** \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Use this cell to verify that all the splits from stratified shuffle split are different\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Discussion (train_test_split and KFold)\n",
    "There is an identical match between the split for train_test_split and one of the splits for KFold. \n",
    "\n",
    "**Task:**\n",
    "1. [1 pt] Using the code cell below, verify that the split is indeed identical. (Tip: use np.all(...), where ... is code you fill in yourself.)\n",
    "\n",
    "2. [1 pt] Why does this identical match happen? What settings or function/method arguments explain the occurence of this match?\n",
    "\n",
    "    **Ans:** \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Use this cell to verify that one of the splits from train_test_split and KFold are the same\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Cross Validation\n",
    "\n",
    "### 2.1 sklearn corss val score\n",
    "**Task:**\n",
    "1. [2 pt] Use `sklearn.model_selection.cross_val_score` to perform cross validation on decision tree classifier\n",
    "    - Define your DecisionTreeClassifier as `clf`.\n",
    "    - Set `max_depth=9` and `random_state=0` in your DecisionTreeClassifier object.\n",
    "    - Perform a 3-fold validation in `cross_val_score`.\n",
    "    - Print the cross validation scores, this should be an array of three elements.\n",
    "\n",
    "Note: You may not have done trees by the time you are doing this homework... Luckily you don't need to know anything about them for this section!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "clf = DecisionTreeClassifier(max_depth=None,random_state=None) # TODO\n",
    "cross_val_score(clf,X,y,cv=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 \"Manual\" cross val score \n",
    "**Task:**\n",
    "\n",
    "Run the code cell below.\n",
    "\n",
    "Based on the lecture Jupyter notebooks, the code below *should be* what the `cross_val_score` function performs. If it is what `cross_val_score` function is actually performing, we ought to see the same three validation scores printed.\n",
    "\n",
    "1. [1 pt] Read the documentation for [sklearn.model_selection.cross_val_score](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html). Pay attention to the description in the \"cv\" parameter. Why isn't the code below performing as we expected?\n",
    "\n",
    "    **Ans:** \n",
    "\n",
    "2. [1 pt] Based on what you found was wrong with the code below, make a change to the splitting method (it may not be onethat we have previously discussed before, so read the documentation carefully) and print out the new cross validation scores. Make sure they match the previous cell. You should not need to change anything in the for-loop, just the code before it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_fold = KFold(n_splits=3, shuffle=False)\n",
    "\n",
    "# ---------- DO NOT CHANGE CODE HERE ---------\n",
    "for k, (train, test) in enumerate(k_fold.split(X,y)):\n",
    "    clf.fit(X[train],y[train])\n",
    "    ypred = clf.predict(X[test])\n",
    "    print ( clf.score(X[test],y[test]) )\n",
    "# --------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 SVM Implementation\n",
    "In this section you will use sklearns SVM package to create an SVM classifier and then test it on different types of data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------- RUN BUT DO NOT CHANGE -------------------\n",
    "from sklearn import svm\n",
    "from sklearn.datasets import make_moons\n",
    "np.random.seed(1)\n",
    "\n",
    "def generate_data(s = 2):\n",
    "    X, y = make_moons(n_samples = 600, noise = .15, random_state = 10)\n",
    "    X1, X2 = X[np.where(y==0)] + s, X[np.where(y==1)]\n",
    "    y1, y2 = y[np.where(y==0)], y[np.where(y==1)]\n",
    "    y = np.hstack([y1,y2])\n",
    "    X = np.vstack([X1,X2])\n",
    "    return train_test_split(X, y, test_size=1/3)\n",
    "# -------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Fitting the SVM\n",
    "\n",
    "Complete the `SVM_Train` function below\n",
    "\n",
    "**Tasks**\n",
    "- [1 pt] Initialize a classifier `clf` using `svm.SVC`, make sure to set the kernel to `kernelType`\n",
    "- [1 pt] Fit the classifier on `X` and `y`\n",
    "- [1 pt] Return the fitted classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM_train(X,y,kernelType = \"linear\"):\n",
    "    # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the plotting function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- RUN THIS CODE DO NOT EDIT -----------------------\n",
    "def SVM_plot(X,y,error,clf):\n",
    "\n",
    "    # Create grid to evaluate model\n",
    "    xx = np.linspace(X[:,0].min()-0.5, X[:,0].max()+0.5, 30)\n",
    "    yy = np.linspace(X[:,1].min()-0.5, X[:,1].max()+0.5, 30)\n",
    "\n",
    "    YY, XX = np.meshgrid(yy, xx)\n",
    "    xy = np.vstack([XX.ravel(), YY.ravel()]).T\n",
    "    Z = clf.decision_function(xy).reshape(XX.shape)\n",
    "\n",
    "    # Plot decision boundary and margins\n",
    "    plt.contour(XX, YY, Z, colors='k', levels=[-1, 0, 1], alpha=0.5, linestyles=['--', '-', '--'])\n",
    "\n",
    "    plt.scatter(X[:,0], X[:,1], c=y, edgecolors = error)\n",
    "    plt.show()\n",
    "# -------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Accuracy\n",
    "\n",
    "Complete the accuracy function below\n",
    "\n",
    "**Tasks** \n",
    "\n",
    "- [3 pt] Complete the function to return the percentage of points that were classified correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true,y_pred):\n",
    "    # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Testing\n",
    "\n",
    "Complete the for loop to test the SVM classifier in a few different situations\n",
    "\n",
    "**Tasks**\n",
    "For each iteration the loop should:\n",
    "- [2 pt] Use `SVM_train` to fit a classifier `clf` on `X_train` and `y_train`\n",
    "    - Note: Make sure to set `kernelType` to `\"linear\"`\n",
    "- [1 pt] Predict `y_pred` using this classifier and `X_test`\n",
    "- [1 pt] Print the accuracy `y_pred` when compared to `y_test` (the true values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in [5, 2, .5, .1, 0]:\n",
    "    X_train, X_test, y_train, y_test = generate_data(s)\n",
    "    \n",
    "    clf = None # TODO\n",
    "    y_pred = None # TODO\n",
    "    \n",
    "    err = np.where(np.abs(y_test - y_pred)==0, \"None\", \"red\") # This is just for plotting purposes later\n",
    "    SVM_plot(X = X_test,y = y_pred, error=err, clf = clf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.4 Discussion\n",
    "\n",
    "Note what is happening as the data changes.\n",
    "\n",
    "[2 pt] As the data changes, what about our SVM implementation causes it to classify more poorly despite there still being visually distinct clusters?\n",
    "- Note that incorrecly classifier points are highlighted in red\n",
    "\n",
    "**Ans** \n",
    "\n",
    "[1 pt] How would you recommend that, while still using an SVM, we change either our training data or our classifier to better classify data like this?\n",
    "- (This is a tough problem and there are many correct answers we just want to see that you have thought about it a little)\n",
    "\n",
    "**Ans** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.5 Changing the kernel\n",
    "\n",
    "Complete the following two code blocks by training the classifier on `X_train`, `y_train` with different kernels\n",
    "\n",
    "**Tasks**\n",
    "- [1 pt] In the first code block set the kernel to `\"poly\"`\n",
    "- [1 pt] In the second code block set the kernel to `\"rbf\"`\n",
    "\n",
    "Observe what changes in the plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Use an polynomial kernel\n",
    "X_train, X_test, y_train, y_test = generate_data(.1)\n",
    "\n",
    "clf = # TODO\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "print(accuracy(y_test,y_pred))\n",
    "err = np.where(np.abs(y_test - y_pred)==0, \"None\", \"red\")\n",
    "SVM_plot(X = X_test,y = y_pred, error = err, clf = clf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Use a radial basis kernel\n",
    "X_train, X_test, y_train, y_test = generate_data(.1)\n",
    "\n",
    "clf = # TODO\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "print(accuracy(y_test,y_pred))\n",
    "err = np.where(np.abs(y_test - y_pred)==0, \"None\", \"red\")\n",
    "SVM_plot(X = X_test,y = y_pred, error = err, clf = clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Discussion\n",
    "\n",
    "[1 pt] What did you observe in the plots using the different kernels? Why might this be?\n",
    "\n",
    "**Ans** "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
